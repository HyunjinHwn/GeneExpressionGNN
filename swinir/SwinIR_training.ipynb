{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdJOIjQPrXiG"
   },
   "source": [
    "SwinIR training code\n",
    "\n",
    "    - Check if the runtime type is set to GPU (A100, L4, or T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12310,
     "status": "ok",
     "timestamp": 1733734517891,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "1-5yZoPMHxIW",
    "outputId": "aa8107ce-7a29-49d6-b6ef-c2267692a513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/294.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!cp -r /content/drive/MyDrive/KAIR_L1000 /content/ # copy the SwinIR codes\n",
    "!pip install -r /content/KAIR_L1000/requirement.txt --quiet # install required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1733734534092,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "zvhoNxtQj5S_"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/option.json /content/\n",
    "# You may upload the option.json file to the colab local storage directly\n",
    "# by dragging-and-dropping your file onto the file browser on the left panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156344,
     "status": "ok",
     "timestamp": 1733737915244,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "OlrpaP1AKB5J",
    "outputId": "7136fcb2-78d6-44a3-c054-ddc65bd73941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0\n",
      "number of GPUs is: 1\n",
      "LogHandlers setup!\n",
      "24-12-09 08:59:23.726 :   task: SwinIR\n",
      "  model: plain\n",
      "  gpu_ids: [0]\n",
      "  dist: False\n",
      "  scale: 4\n",
      "  n_channels: 1\n",
      "  path:[\n",
      "    root: /content/drive/MyDrive/KTH/swinIRtest_1209\n",
      "    pretrained_netG: None\n",
      "    pretrained_netE: None\n",
      "    pretrained_optimizerG: None\n",
      "    task: /content/drive/MyDrive/KTH/swinIRtest_1209/SwinIR\n",
      "    log: /content/drive/MyDrive/KTH/swinIRtest_1209/SwinIR\n",
      "    options: /content/drive/MyDrive/KTH/swinIRtest_1209/SwinIR/options\n",
      "    models: /content/drive/MyDrive/KTH/swinIRtest_1209/SwinIR/models\n",
      "    images: /content/drive/MyDrive/KTH/swinIRtest_1209/SwinIR/images\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: train_dataset\n",
      "      dataset_type: sr\n",
      "      dataroot_H: /content/image/RNAseq/train\n",
      "      dataroot_L: /content/image/L1000/train\n",
      "      H_size: 96\n",
      "      dataloader_shuffle: True\n",
      "      dataloader_num_workers: 2\n",
      "      dataloader_batch_size: 32\n",
      "      phase: train\n",
      "      scale: 4\n",
      "      n_channels: 1\n",
      "    ]\n",
      "    test:[\n",
      "      name: test_dataset\n",
      "      dataset_type: sr\n",
      "      dataroot_H: /content/image/RNAseq/valid\n",
      "      dataroot_L: /content/image/L1000/valid\n",
      "      phase: test\n",
      "      scale: 4\n",
      "      n_channels: 1\n",
      "    ]\n",
      "  ]\n",
      "  netG:[\n",
      "    net_type: swinir\n",
      "    upscale: 4\n",
      "    in_chans: 1\n",
      "    img_size: 24\n",
      "    window_size: 4\n",
      "    img_range: 1.0\n",
      "    depths: [6, 6, 6, 6, 6, 6]\n",
      "    embed_dim: 180\n",
      "    num_heads: [6, 6, 6, 6, 6, 6]\n",
      "    mlp_ratio: 2\n",
      "    upsampler: pixelshuffle\n",
      "    resi_connection: 1conv\n",
      "    init_type: default\n",
      "    scale: 4\n",
      "  ]\n",
      "  train:[\n",
      "    G_lossfn_type: l1\n",
      "    G_lossfn_weight: 1.0\n",
      "    E_decay: 0.999\n",
      "    G_optimizer_type: adam\n",
      "    G_optimizer_lr: 0.0002\n",
      "    G_optimizer_wd: 0\n",
      "    G_optimizer_clipgrad: None\n",
      "    G_optimizer_reuse: True\n",
      "    G_scheduler_type: MultiStepLR\n",
      "    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]\n",
      "    G_scheduler_gamma: 0.5\n",
      "    G_regularizer_orthstep: None\n",
      "    G_regularizer_clipstep: None\n",
      "    G_param_strict: True\n",
      "    E_param_strict: True\n",
      "    checkpoint_test: 5000\n",
      "    checkpoint_save: 5000\n",
      "    checkpoint_print: 1000\n",
      "    F_feature_layer: 34\n",
      "    F_weights: 1.0\n",
      "    F_lossfn_type: l1\n",
      "    F_use_input_norm: True\n",
      "    F_use_range_norm: False\n",
      "    G_optimizer_betas: [0.9, 0.999]\n",
      "    G_scheduler_restart_weights: 1\n",
      "  ]\n",
      "  opt_path: /content/option.json\n",
      "  is_train: True\n",
      "  merge_bn: False\n",
      "  merge_bn_startpoint: -1\n",
      "  find_unused_parameters: True\n",
      "  use_static_graph: False\n",
      "  num_gpu: 1\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "\n",
      "Random seed: 853\n",
      "Dataset [DatasetSR - train_dataset] is created.\n",
      "24-12-09 08:59:23.741 : Number of train images: 2,500, iters: 79\n",
      "Dataset [DatasetSR - test_dataset] is created.\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Pass this initialization! Initialization was done during network definition!\n",
      "Pass this initialization! Initialization was done during network definition!\n",
      "Training model [ModelPlain] is created.\n",
      "Copying model for E ...\n",
      "24-12-09 08:59:25.595 : \n",
      "Networks name: SwinIR\n",
      "Params number: 11857789\n",
      "Net structure:\n",
      "SwinIR(\n",
      "  (conv_first): Conv2d(1, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (patch_unembed): PatchUnEmbed()\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.003)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.006)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.009)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.011)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.014)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (1): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.017)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.020)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.023)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.026)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.029)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.031)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (2): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.034)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.037)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.040)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.043)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.046)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.049)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (3): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.051)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.054)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.057)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.060)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.063)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.066)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (4): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.069)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.071)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.074)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.077)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.080)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.083)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (5): RSTB(\n",
      "      (residual_group): BasicLayer(\n",
      "        dim=180, input_resolution=(24, 24), depth=6\n",
      "        (blocks): ModuleList(\n",
      "          (0): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.086)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.089)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.094)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=0, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.097)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            dim=180, input_resolution=(24, 24), num_heads=6, window_size=4, shift_size=2, mlp_ratio=2\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              dim=180, window_size=(4, 4), num_heads=6\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path): DropPath(drop_prob=0.100)\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_before_upsample): Sequential(\n",
      "    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (upsample): Upsample(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): PixelShuffle(upscale_factor=2)\n",
      "  )\n",
      "  (conv_last): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "\n",
      "/content/KAIR_harim/models/model_base.py:136: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  msg += ' | {:>6.3f} | {:>6.3f} | {:>6.3f} | {:>6.3f} | {} || {:s}'.format(v.mean(), v.min(), v.max(), v.std(), v.shape, name) + '\\n'\n",
      "24-12-09 08:59:25.763 : \n",
      " |  mean  |  min   |  max   |  std   || shape               \n",
      " | -0.005 | -0.333 |  0.333 |  0.194 | torch.Size([180, 1, 3, 3]) || conv_first.weight\n",
      " |  0.019 | -0.333 |  0.333 |  0.189 | torch.Size([180]) || conv_first.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || patch_embed.norm.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || patch_embed.norm.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm1.bias\n",
      " | -0.001 | -0.051 |  0.048 |  0.020 | torch.Size([49, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.0.attn.relative_position_index\n",
      " |  0.000 | -0.102 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.0.attn.qkv.bias\n",
      " | -0.000 | -0.085 |  0.078 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.norm2.bias\n",
      " |  0.000 | -0.087 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.0.mlp.fc1.bias\n",
      " |  0.000 | -0.075 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.0.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm1.bias\n",
      " | -0.000 | -0.054 |  0.061 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.1.attn.relative_position_index\n",
      " | -0.000 | -0.085 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.1.attn.qkv.bias\n",
      " |  0.000 | -0.083 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.norm2.bias\n",
      " |  0.000 | -0.088 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.1.mlp.fc1.bias\n",
      " |  0.000 | -0.086 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm1.bias\n",
      " |  0.000 | -0.066 |  0.050 |  0.020 | torch.Size([49, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.2.attn.relative_position_index\n",
      " | -0.000 | -0.084 |  0.079 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.087 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.norm2.bias\n",
      " | -0.000 | -0.083 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.2.mlp.fc1.bias\n",
      " | -0.000 | -0.087 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.0.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm1.bias\n",
      " |  0.002 | -0.046 |  0.055 |  0.018 | torch.Size([49, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.3.attn.relative_position_index\n",
      " |  0.000 | -0.084 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.3.attn.qkv.bias\n",
      " |  0.000 | -0.083 |  0.092 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.norm2.bias\n",
      " |  0.000 | -0.083 |  0.078 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.3.mlp.fc1.bias\n",
      " |  0.000 | -0.092 |  0.089 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm1.bias\n",
      " |  0.001 | -0.056 |  0.057 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.4.attn.relative_position_index\n",
      " |  0.000 | -0.087 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.4.attn.qkv.bias\n",
      " |  0.000 | -0.077 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.norm2.bias\n",
      " |  0.000 | -0.086 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.4.mlp.fc1.bias\n",
      " |  0.000 | -0.088 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.0.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm1.bias\n",
      " | -0.001 | -0.054 |  0.063 |  0.021 | torch.Size([49, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.0.residual_group.blocks.5.attn.relative_position_index\n",
      " |  0.000 | -0.083 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.0.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.0.residual_group.blocks.5.attn.qkv.bias\n",
      " | -0.000 | -0.081 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.0.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.norm2.bias\n",
      " |  0.000 | -0.083 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.0.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.0.residual_group.blocks.5.mlp.fc1.bias\n",
      " |  0.000 | -0.092 |  0.089 |  0.020 | torch.Size([180, 360]) || layers.0.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.0.residual_group.blocks.5.mlp.fc2.bias\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.0.conv.weight\n",
      " |  0.000 | -0.024 |  0.025 |  0.014 | torch.Size([180]) || layers.0.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm1.bias\n",
      " | -0.002 | -0.059 |  0.047 |  0.018 | torch.Size([49, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.0.attn.relative_position_index\n",
      " | -0.000 | -0.088 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.0.attn.qkv.bias\n",
      " |  0.000 | -0.089 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.norm2.bias\n",
      " | -0.000 | -0.083 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.0.mlp.fc1.bias\n",
      " |  0.000 | -0.081 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.1.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm1.bias\n",
      " |  0.000 | -0.052 |  0.052 |  0.020 | torch.Size([49, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.1.attn.relative_position_index\n",
      " |  0.000 | -0.081 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.1.attn.qkv.bias\n",
      " | -0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.norm2.bias\n",
      " | -0.000 | -0.078 |  0.099 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.1.mlp.fc1.bias\n",
      " |  0.000 | -0.086 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm1.bias\n",
      " | -0.001 | -0.056 |  0.064 |  0.021 | torch.Size([49, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.2.attn.relative_position_index\n",
      " |  0.000 | -0.084 |  0.103 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.083 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.norm2.bias\n",
      " |  0.000 | -0.086 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.2.mlp.fc1.bias\n",
      " |  0.000 | -0.093 |  0.094 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.1.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm1.bias\n",
      " | -0.000 | -0.047 |  0.056 |  0.019 | torch.Size([49, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.3.attn.relative_position_index\n",
      " |  0.000 | -0.106 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.3.attn.qkv.bias\n",
      " |  0.000 | -0.075 |  0.099 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.norm2.bias\n",
      " |  0.000 | -0.084 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.3.mlp.fc1.bias\n",
      " | -0.000 | -0.084 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm1.bias\n",
      " | -0.000 | -0.055 |  0.069 |  0.019 | torch.Size([49, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.4.attn.relative_position_index\n",
      " | -0.000 | -0.092 |  0.078 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.4.attn.qkv.bias\n",
      " |  0.000 | -0.082 |  0.079 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.norm2.bias\n",
      " | -0.000 | -0.086 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.4.mlp.fc1.bias\n",
      " | -0.000 | -0.080 |  0.085 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.1.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm1.bias\n",
      " | -0.001 | -0.060 |  0.051 |  0.019 | torch.Size([49, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.1.residual_group.blocks.5.attn.relative_position_index\n",
      " | -0.000 | -0.086 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.1.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.1.residual_group.blocks.5.attn.qkv.bias\n",
      " | -0.000 | -0.081 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.1.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.norm2.bias\n",
      " |  0.000 | -0.082 |  0.078 |  0.020 | torch.Size([360, 180]) || layers.1.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.1.residual_group.blocks.5.mlp.fc1.bias\n",
      " |  0.000 | -0.079 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.1.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.1.residual_group.blocks.5.mlp.fc2.bias\n",
      " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.1.conv.weight\n",
      " | -0.001 | -0.024 |  0.024 |  0.014 | torch.Size([180]) || layers.1.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm1.bias\n",
      " | -0.000 | -0.051 |  0.061 |  0.020 | torch.Size([49, 6]) || layers.2.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.0.attn.relative_position_index\n",
      " | -0.000 | -0.084 |  0.093 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.0.attn.qkv.bias\n",
      " | -0.000 | -0.078 |  0.077 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.norm2.bias\n",
      " |  0.000 | -0.082 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.0.mlp.fc1.bias\n",
      " |  0.000 | -0.087 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.2.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm1.bias\n",
      " |  0.001 | -0.065 |  0.057 |  0.020 | torch.Size([49, 6]) || layers.2.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.1.attn.relative_position_index\n",
      " |  0.000 | -0.081 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.1.attn.qkv.bias\n",
      " | -0.000 | -0.090 |  0.088 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.norm2.bias\n",
      " |  0.000 | -0.089 |  0.083 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.1.mlp.fc1.bias\n",
      " |  0.000 | -0.092 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm1.bias\n",
      " |  0.002 | -0.046 |  0.065 |  0.018 | torch.Size([49, 6]) || layers.2.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.2.attn.relative_position_index\n",
      " |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.098 |  0.092 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.norm2.bias\n",
      " |  0.000 | -0.084 |  0.076 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.2.mlp.fc1.bias\n",
      " |  0.000 | -0.084 |  0.076 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.2.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm1.bias\n",
      " | -0.000 | -0.063 |  0.062 |  0.021 | torch.Size([49, 6]) || layers.2.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.3.attn.relative_position_index\n",
      " | -0.000 | -0.095 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.3.attn.qkv.bias\n",
      " |  0.000 | -0.085 |  0.088 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.norm2.bias\n",
      " | -0.000 | -0.081 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.3.mlp.fc1.bias\n",
      " |  0.000 | -0.087 |  0.093 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm1.bias\n",
      " |  0.001 | -0.056 |  0.066 |  0.021 | torch.Size([49, 6]) || layers.2.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.4.attn.relative_position_index\n",
      " | -0.000 | -0.087 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.4.attn.qkv.bias\n",
      " |  0.000 | -0.084 |  0.079 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.norm2.bias\n",
      " | -0.000 | -0.095 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.4.mlp.fc1.bias\n",
      " |  0.000 | -0.093 |  0.078 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.2.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm1.bias\n",
      " | -0.000 | -0.066 |  0.055 |  0.020 | torch.Size([49, 6]) || layers.2.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.2.residual_group.blocks.5.attn.relative_position_index\n",
      " |  0.000 | -0.085 |  0.083 |  0.020 | torch.Size([540, 180]) || layers.2.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.2.residual_group.blocks.5.attn.qkv.bias\n",
      " |  0.000 | -0.073 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.2.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.norm2.bias\n",
      " |  0.000 | -0.087 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.2.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.2.residual_group.blocks.5.mlp.fc1.bias\n",
      " | -0.000 | -0.097 |  0.076 |  0.020 | torch.Size([180, 360]) || layers.2.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.2.residual_group.blocks.5.mlp.fc2.bias\n",
      " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.2.conv.weight\n",
      " | -0.000 | -0.025 |  0.024 |  0.014 | torch.Size([180]) || layers.2.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm1.bias\n",
      " | -0.000 | -0.065 |  0.053 |  0.018 | torch.Size([49, 6]) || layers.3.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.0.attn.relative_position_index\n",
      " | -0.000 | -2.000 |  0.084 |  0.021 | torch.Size([540, 180]) || layers.3.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.0.attn.qkv.bias\n",
      " |  0.000 | -0.083 |  0.090 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.norm2.bias\n",
      " |  0.000 | -0.084 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.0.mlp.fc1.bias\n",
      " | -0.000 | -0.084 |  0.083 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.3.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm1.bias\n",
      " | -0.001 | -0.066 |  0.049 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.1.attn.relative_position_index\n",
      " |  0.000 | -0.087 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.1.attn.qkv.bias\n",
      " |  0.000 | -0.075 |  0.102 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.norm2.bias\n",
      " | -0.000 | -0.079 |  0.092 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.1.mlp.fc1.bias\n",
      " | -0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm1.bias\n",
      " | -0.000 | -0.059 |  0.053 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.2.attn.relative_position_index\n",
      " | -0.000 | -0.085 |  0.085 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.090 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.norm2.bias\n",
      " | -0.000 | -0.077 |  0.090 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.2.mlp.fc1.bias\n",
      " | -0.000 | -0.086 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.3.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm1.bias\n",
      " |  0.001 | -0.061 |  0.054 |  0.020 | torch.Size([49, 6]) || layers.3.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.3.attn.relative_position_index\n",
      " |  0.000 | -0.074 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.3.attn.qkv.bias\n",
      " |  0.000 | -0.084 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.norm2.bias\n",
      " |  0.000 | -0.075 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.3.mlp.fc1.bias\n",
      " | -0.000 | -0.087 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm1.bias\n",
      " |  0.001 | -0.058 |  0.067 |  0.021 | torch.Size([49, 6]) || layers.3.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.4.attn.relative_position_index\n",
      " | -0.000 | -0.082 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.4.attn.qkv.bias\n",
      " |  0.000 | -0.083 |  0.088 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.norm2.bias\n",
      " | -0.000 | -0.081 |  0.086 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.4.mlp.fc1.bias\n",
      " | -0.000 | -0.086 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.3.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm1.bias\n",
      " | -0.002 | -0.075 |  0.069 |  0.021 | torch.Size([49, 6]) || layers.3.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.3.residual_group.blocks.5.attn.relative_position_index\n",
      " | -0.000 | -0.083 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.3.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.3.residual_group.blocks.5.attn.qkv.bias\n",
      " |  0.000 | -0.082 |  0.085 |  0.020 | torch.Size([180, 180]) || layers.3.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.norm2.bias\n",
      " |  0.000 | -0.086 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.3.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.3.residual_group.blocks.5.mlp.fc1.bias\n",
      " | -0.000 | -0.083 |  0.088 |  0.020 | torch.Size([180, 360]) || layers.3.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.3.residual_group.blocks.5.mlp.fc2.bias\n",
      " | -0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.3.conv.weight\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180]) || layers.3.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm1.bias\n",
      " | -0.001 | -0.045 |  0.063 |  0.019 | torch.Size([49, 6]) || layers.4.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.0.attn.relative_position_index\n",
      " | -0.000 | -0.085 |  0.090 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.0.attn.qkv.bias\n",
      " | -0.000 | -0.087 |  0.073 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.norm2.bias\n",
      " |  0.000 | -0.080 |  0.087 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.0.mlp.fc1.bias\n",
      " | -0.000 | -0.073 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.4.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm1.bias\n",
      " |  0.001 | -0.057 |  0.056 |  0.020 | torch.Size([49, 6]) || layers.4.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.1.attn.relative_position_index\n",
      " | -0.000 | -0.084 |  0.079 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.1.attn.qkv.bias\n",
      " |  0.000 | -0.082 |  0.081 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.norm2.bias\n",
      " |  0.000 | -0.086 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.1.mlp.fc1.bias\n",
      " | -0.000 | -0.084 |  0.092 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm1.bias\n",
      " |  0.001 | -0.045 |  0.054 |  0.020 | torch.Size([49, 6]) || layers.4.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.2.attn.relative_position_index\n",
      " | -0.000 | -0.084 |  0.097 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.089 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.norm2.bias\n",
      " | -0.000 | -0.092 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.2.mlp.fc1.bias\n",
      " |  0.000 | -0.086 |  0.082 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.4.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm1.bias\n",
      " |  0.001 | -0.051 |  0.067 |  0.020 | torch.Size([49, 6]) || layers.4.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.3.attn.relative_position_index\n",
      " | -0.000 | -0.096 |  0.088 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.3.attn.qkv.bias\n",
      " | -0.000 | -0.075 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.norm2.bias\n",
      " |  0.000 | -0.087 |  0.078 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.3.mlp.fc1.bias\n",
      " |  0.000 | -0.084 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm1.bias\n",
      " | -0.000 | -0.056 |  0.054 |  0.021 | torch.Size([49, 6]) || layers.4.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.4.attn.relative_position_index\n",
      " |  0.000 | -0.083 |  0.082 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.4.attn.qkv.bias\n",
      " |  0.000 | -0.079 |  0.084 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.norm2.bias\n",
      " | -0.000 | -0.094 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.4.mlp.fc1.bias\n",
      " | -0.000 | -0.084 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.4.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm1.bias\n",
      " | -0.001 | -0.061 |  0.060 |  0.020 | torch.Size([49, 6]) || layers.4.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.4.residual_group.blocks.5.attn.relative_position_index\n",
      " | -0.000 | -0.083 |  0.091 |  0.020 | torch.Size([540, 180]) || layers.4.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.4.residual_group.blocks.5.attn.qkv.bias\n",
      " | -0.000 | -0.078 |  0.075 |  0.020 | torch.Size([180, 180]) || layers.4.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.norm2.bias\n",
      " | -0.000 | -0.091 |  0.084 |  0.020 | torch.Size([360, 180]) || layers.4.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.4.residual_group.blocks.5.mlp.fc1.bias\n",
      " | -0.000 | -0.080 |  0.090 |  0.020 | torch.Size([180, 360]) || layers.4.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.4.residual_group.blocks.5.mlp.fc2.bias\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.4.conv.weight\n",
      " | -0.000 | -0.025 |  0.025 |  0.015 | torch.Size([180]) || layers.4.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm1.bias\n",
      " |  0.000 | -0.057 |  0.070 |  0.020 | torch.Size([49, 6]) || layers.5.residual_group.blocks.0.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.0.attn.relative_position_index\n",
      " | -0.000 | -0.096 |  0.086 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.0.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.0.attn.qkv.bias\n",
      " |  0.000 | -0.085 |  0.086 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.0.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.norm2.bias\n",
      " |  0.000 | -0.089 |  0.089 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.0.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.0.mlp.fc1.bias\n",
      " | -0.000 | -0.081 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.0.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.0.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.5.residual_group.blocks.1.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm1.bias\n",
      " |  0.000 | -0.058 |  0.060 |  0.021 | torch.Size([49, 6]) || layers.5.residual_group.blocks.1.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.1.attn.relative_position_index\n",
      " | -0.000 | -0.085 |  0.089 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.1.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.1.attn.qkv.bias\n",
      " |  0.000 | -0.095 |  0.076 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.1.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.norm2.bias\n",
      " | -0.000 | -0.090 |  0.081 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.1.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.1.mlp.fc1.bias\n",
      " | -0.000 | -0.085 |  0.091 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.1.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.1.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm1.bias\n",
      " | -0.001 | -0.061 |  0.043 |  0.020 | torch.Size([49, 6]) || layers.5.residual_group.blocks.2.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.2.attn.relative_position_index\n",
      " | -0.000 | -0.082 |  0.087 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.2.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.2.attn.qkv.bias\n",
      " | -0.000 | -0.087 |  0.083 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.2.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.norm2.bias\n",
      " |  0.000 | -0.085 |  0.080 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.2.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.2.mlp.fc1.bias\n",
      " |  0.000 | -0.082 |  0.084 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.2.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.2.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.5.residual_group.blocks.3.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm1.bias\n",
      " | -0.000 | -0.059 |  0.056 |  0.020 | torch.Size([49, 6]) || layers.5.residual_group.blocks.3.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.3.attn.relative_position_index\n",
      " | -0.000 | -0.088 |  0.092 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.3.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.3.attn.qkv.bias\n",
      " |  0.000 | -0.075 |  0.080 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.3.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.norm2.bias\n",
      " | -0.000 | -0.092 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.3.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.3.mlp.fc1.bias\n",
      " | -0.000 | -0.088 |  0.079 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.3.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.3.mlp.fc2.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm1.bias\n",
      " |  0.001 | -0.073 |  0.063 |  0.021 | torch.Size([49, 6]) || layers.5.residual_group.blocks.4.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.4.attn.relative_position_index\n",
      " |  0.000 | -0.082 |  0.092 |  0.020 | torch.Size([540, 180]) || layers.5.residual_group.blocks.4.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.4.attn.qkv.bias\n",
      " | -0.000 | -0.085 |  0.079 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.4.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.norm2.bias\n",
      " |  0.000 | -0.083 |  0.085 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.4.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.4.mlp.fc1.bias\n",
      " | -0.000 | -0.086 |  0.087 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.4.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.4.mlp.fc2.bias\n",
      " | -15.972 | -100.000 |  0.000 | 36.637 | torch.Size([36, 16, 16]) || layers.5.residual_group.blocks.5.attn_mask\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm1.bias\n",
      " | -0.000 | -0.059 |  0.056 |  0.020 | torch.Size([49, 6]) || layers.5.residual_group.blocks.5.attn.relative_position_bias_table\n",
      " | 24.000 |  0.000 | 48.000 | 11.202 | torch.Size([16, 16]) || layers.5.residual_group.blocks.5.attn.relative_position_index\n",
      " | -0.000 | -2.000 |  0.085 |  0.021 | torch.Size([540, 180]) || layers.5.residual_group.blocks.5.attn.qkv.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([540]) || layers.5.residual_group.blocks.5.attn.qkv.bias\n",
      " |  0.000 | -0.080 |  0.076 |  0.020 | torch.Size([180, 180]) || layers.5.residual_group.blocks.5.attn.proj.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.attn.proj.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.norm2.bias\n",
      " |  0.000 | -0.079 |  0.082 |  0.020 | torch.Size([360, 180]) || layers.5.residual_group.blocks.5.mlp.fc1.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([360]) || layers.5.residual_group.blocks.5.mlp.fc1.bias\n",
      " | -0.000 | -0.087 |  0.086 |  0.020 | torch.Size([180, 360]) || layers.5.residual_group.blocks.5.mlp.fc2.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || layers.5.residual_group.blocks.5.mlp.fc2.bias\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || layers.5.conv.weight\n",
      " |  0.002 | -0.024 |  0.025 |  0.015 | torch.Size([180]) || layers.5.conv.bias\n",
      " |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([180]) || norm.weight\n",
      " |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([180]) || norm.bias\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([180, 180, 3, 3]) || conv_after_body.weight\n",
      " |  0.001 | -0.025 |  0.024 |  0.015 | torch.Size([180]) || conv_after_body.bias\n",
      " |  0.000 | -0.025 |  0.025 |  0.014 | torch.Size([64, 180, 3, 3]) || conv_before_upsample.0.weight\n",
      " | -0.003 | -0.025 |  0.024 |  0.014 | torch.Size([64]) || conv_before_upsample.0.bias\n",
      " |  0.000 | -0.042 |  0.042 |  0.024 | torch.Size([256, 64, 3, 3]) || upsample.0.weight\n",
      " | -0.001 | -0.042 |  0.041 |  0.023 | torch.Size([256]) || upsample.0.bias\n",
      " | -0.000 | -0.042 |  0.042 |  0.024 | torch.Size([256, 64, 3, 3]) || upsample.2.weight\n",
      " |  0.000 | -0.041 |  0.042 |  0.023 | torch.Size([256]) || upsample.2.bias\n",
      " |  0.001 | -0.041 |  0.042 |  0.024 | torch.Size([1, 64, 3, 3]) || conv_last.weight\n",
      " |  0.027 |  0.027 |  0.027 |    nan | torch.Size([1]) || conv_last.bias\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "[rank0]:[W1209 08:59:33.778544341 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:595: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  _warn_get_lr_called_within_step(self)\n",
      "24-12-09 08:59:34.447 : <epoch:  0, iter:       1, lr:2.000e-04> G_loss: 2.020e-01 \n",
      "24-12-09 09:04:30.997 : <epoch: 12, iter:   1,000, lr:2.000e-04> G_loss: 1.107e-01 \n",
      "24-12-09 09:09:35.273 : <epoch: 25, iter:   2,000, lr:2.000e-04> G_loss: 6.437e-02 \n",
      "24-12-09 09:14:39.797 : <epoch: 38, iter:   3,000, lr:2.000e-04> G_loss: 5.343e-02 \n",
      "24-12-09 09:19:43.853 : <epoch: 51, iter:   4,000, lr:2.000e-04> G_loss: 4.526e-02 \n",
      "24-12-09 09:24:48.307 : <epoch: 64, iter:   5,000, lr:2.000e-04> G_loss: 4.231e-02 \n",
      "24-12-09 09:24:48.308 : Saving the model.\n",
      "24-12-09 09:25:42.844 : <epoch: 64, iter:   5,000, Average PSNR : 0.0694, Average PCC : 0.8647, Average SCC : 0.8632\n",
      "\n",
      "24-12-09 09:30:39.780 : <epoch: 76, iter:   6,000, lr:2.000e-04> G_loss: 4.383e-02 \n",
      "24-12-09 09:35:45.167 : <epoch: 89, iter:   7,000, lr:2.000e-04> G_loss: 4.078e-02 \n",
      "24-12-09 09:40:51.018 : <epoch:102, iter:   8,000, lr:2.000e-04> G_loss: 3.781e-02 \n",
      "24-12-09 09:45:59.357 : <epoch:115, iter:   9,000, lr:2.000e-04> G_loss: 3.745e-02 \n",
      "24-12-09 09:51:14.316 : <epoch:128, iter:  10,000, lr:2.000e-04> G_loss: 3.768e-02 \n",
      "24-12-09 09:51:14.317 : Saving the model.\n",
      "W1209 09:51:51.692000 5090 torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGINT death signal, shutting down workers\n",
      "W1209 09:51:51.693000 5090 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 5113 closing signal SIGINT\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/content/KAIR_harim/main_train_psnr_no_outputs.py\", line 276, in <module>\n",
      "[rank0]:     main()\n",
      "[rank0]:   File \"/content/KAIR_harim/main_train_psnr_no_outputs.py\", line 242, in main\n",
      "[rank0]:     model.test()\n",
      "[rank0]:   File \"/content/KAIR_harim/models/model_plain.py\", line 201, in test\n",
      "[rank0]:     self.netG_forward()\n",
      "[rank0]:   File \"/content/KAIR_harim/models/model_plain.py\", line 158, in netG_forward\n",
      "[rank0]:     self.E = self.netG(self.L)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1643, in forward\n",
      "[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py\", line 1459, in _run_ddp_forward\n",
      "[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 815, in forward\n",
      "[rank0]:     x = self.conv_after_body(self.forward_features(x)) + x\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 798, in forward_features\n",
      "[rank0]:     x = layer(x, x_size)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 482, in forward\n",
      "[rank0]:     return self.patch_embed(self.conv(self.patch_unembed(self.residual_group(x, x_size), x_size))) + x\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 402, in forward\n",
      "[rank0]:     x = blk(x, x_size)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 277, in forward\n",
      "[rank0]:     x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/content/KAIR_harim/models/network_swinir.py\", line 26, in forward\n",
      "[rank0]:     x = self.act(x)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1741, in _call_impl\n",
      "[rank0]:     forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[rank0]: KeyboardInterrupt\n",
      "[rank0]:[W1209 09:51:52.240867184 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 919, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 910, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 260, in launch_agent\n",
      "    result = agent.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py\", line 137, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 696, in run\n",
      "    result = self._invoke_run(role)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 855, in _invoke_run\n",
      "    time.sleep(monitor_interval)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 5090 got signal: 2\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=1 --master_port=1234 /content/KAIR_L1000/main_train_psnr_no_outputs.py --opt /content/option.json  --dist False\n",
    "# This will save the models to the path designated in the option.json file.\n",
    "# If a runtime is disconnected and you want to further train the model, just run the same code from the top.\n",
    "# the train code will look for the most recent checkpoint and continue training.\n",
    "# Note that while the number of iteration is kept, number of epochs is not loaded when running the code again."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnn73ybjExg1PkOKTAicUV",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "12knM-hcfWqmhPExiOXcA_MfyrSos-q9z",
   "provenance": [
    {
     "file_id": "1HrOX_iVsezg3cy2Ej2u31Z-ettAjvfeO",
     "timestamp": 1717121917920
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
