{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cmapPy.pandasGEXpress.parse import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46229,
     "status": "ok",
     "timestamp": 1734485712365,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "RGKDm16gurc_",
    "outputId": "edc1fb84-10d5-47de-802a-9cc1ad95fee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# @title Install requirements and input data\n",
    "!pip -q install -r /content/KAIR_L1000/requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geneid_list(input_file):\n",
    "    # input: txt file with one gene id per one line\n",
    "    # output: a list of string-formatted, newline character-removed gene ids\n",
    "    try:\n",
    "        if input_file.endswith(\".txt\"):\n",
    "            with open(input_file, 'r') as f:\n",
    "                lst = f.readlines()\n",
    "            lst = [l[:-1] for l in lst]\n",
    "            return lst\n",
    "        else:\n",
    "            raise ValueError(\"input file should be a text file\")\n",
    "    except:\n",
    "        raise ValueError(\"input should be a string for a path of gene ID list file\")\n",
    "    \n",
    "def l1000_to_image(input, lmids):\n",
    "    # input: a pandas dataframe of L1000 input data\n",
    "    # lmids: a list of landmark gene ids\n",
    "    # return: a list of numpy arrays with (27x36) shape\n",
    "    # Note that the values are unchanged by this function; \n",
    "    #   so scaling to (0,1) should be done before using this function\n",
    "    num_lm = len(lmids)\n",
    "    sample = input.loc[lmids,:]\n",
    "    lst = []\n",
    "    for i in range(input.shape[1]):\n",
    "        sample_i = sample.iloc[:,i].tolist()\n",
    "        if num_lm == 108:\n",
    "            sample_i = np.reshape(sample_i, (9,12))\n",
    "            out_image = np.repeat(np.repeat(sample_i, 3, axis=0), 3, axis=1)\n",
    "        else:\n",
    "            if num_lm == 970:\n",
    "                sample_i = sample_i + [0,0] # add two zeros at the end to fit in the shape (27x36)\n",
    "            elif num_lm == 486:\n",
    "                sample_i = np.repeat(sample_i, 2)\n",
    "            elif num_lm == 324:\n",
    "                sample_i = np.repeat(sample_i, 3)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid length of lmids: {num_lm}\")\n",
    "\n",
    "            out_image =np.reshape(sample_i, (27,36))\n",
    "        lst.append(out_image)            \n",
    "    return lst\n",
    "\n",
    "def rnaseq_to_image(input, lmids):\n",
    "    # input: a pandas dataframe of RNA-seq ground truth data\n",
    "    # lmids: a list of landmark gene ids\n",
    "    # return: a list of numpy arrays with (108x144) shape\n",
    "    # Note that the values are unchanged by this function; \n",
    "    #   so scaling to (0,1) should be done before using this function\n",
    "    \n",
    "    num_lm = len(lmids)\n",
    "    num_nonlm = input.shape[0] - num_lm\n",
    "    if isinstance(input, pd.Series):\n",
    "        num_cols= 1\n",
    "        input = pd.DataFrame(input)\n",
    "    else:\n",
    "        num_cols = input.shape[1]\n",
    "    lst = []\n",
    "    for i in range(num_cols):\n",
    "        # if num_cols == 1:\n",
    "        #     ith_lm = input.loc[lmids]\n",
    "        #     ith_nonlm = input.drop(index=lmids)\n",
    "        # else:\n",
    "        ith_lm = input.loc[lmids,:].iloc[:,i]\n",
    "        ith_nonlm = input.drop(index=lmids).iloc[:,i]\n",
    "        cnt = 0\n",
    "        \n",
    "        if num_lm == 970:\n",
    "            ith_lm = np.array(ith_lm.tolist()+[0,0])\n",
    "            ith_nonlm = ith_nonlm.tolist() + np.zeros(108*144-972*4-num_nonlm).tolist()\n",
    "            out_image = np.repeat(np.repeat(np.reshape(ith_lm, (27,36)), 4, axis=0),4, axis=1)\n",
    "            if type(ith_nonlm[0])==str:\n",
    "                print(np.array(ith_nonlm).dtype)\n",
    "                out_image = out_image.astype(np.array(ith_nonlm).dtype)\n",
    "            for r in range(108):\n",
    "                for c in range(144):\n",
    "                    if (r%4 in [1,2]) and (c%4 in [1,2]): continue\n",
    "                    else:\n",
    "                        if cnt >= len(ith_nonlm): continue\n",
    "                        out_image[r,c]= ith_nonlm[cnt]\n",
    "                        cnt += 1\n",
    "\n",
    "        elif num_lm == 486:\n",
    "            ith_lm = np.repeat(ith_lm.tolist(), 2)\n",
    "            ith_nonlm = ith_nonlm.tolist() + np.zeros(108*144 - 486*7 - num_nonlm).tolist()\n",
    "            out_image = np.repeat(np.repeat(np.reshape(ith_lm, (27,36)), 4, axis=0), 4, axis=1)\n",
    "            if type(ith_nonlm[0])==str:\n",
    "                print(np.array(ith_nonlm).dtype)\n",
    "                out_image = out_image.astype(np.array(ith_nonlm).dtype)\n",
    "            \n",
    "            for r in range(108):\n",
    "                for c in range(144):\n",
    "                    if (r%4==1 and c%8 in [*range(2,6)]) or (r%4==2 and c%8 in [*range(3,6)]): continue\n",
    "                    else:\n",
    "                        if cnt>= len(ith_nonlm): continue\n",
    "                        out_image[r,c]= ith_nonlm[cnt]\n",
    "                        cnt += 1\n",
    "        elif num_lm == 324:\n",
    "            ith_lm = np.repeat(ith_lm.tolist(), 3)\n",
    "            ith_nonlm = ith_nonlm.tolist() + np.zeros(108*144-324*10-num_nonlm).tolist()\n",
    "            out_image = np.repeat(np.repeat(np.reshape(ith_lm, (27,36)), 4, axis=0), 4, axis=1)\n",
    "            if type(ith_nonlm[0])==str:\n",
    "                print(np.array(ith_nonlm).dtype)\n",
    "                out_image = out_image.astype(np.array(ith_nonlm).dtype)\n",
    "            \n",
    "            for r in range(108):\n",
    "                for c in range(144):\n",
    "                    if (r%4 in [1,2]) and (c%12 in [*range(3,8)]): continue\n",
    "                    else:\n",
    "                        if cnt >= len(ith_nonlm): continue\n",
    "                        out_image[r,c]= ith_nonlm[cnt]\n",
    "                        cnt += 1\n",
    "        elif num_lm == 108:\n",
    "            ith_lm = np.array(ith_lm)\n",
    "            ith_nonlm = ith_nonlm.tolist() + np.zeros(108*144-108*6*5-num_nonlm).tolist()\n",
    "            out_image = np.repeat(np.repeat(np.reshape(ith_lm, (9,12)),12, axis=0),12, axis=1)\n",
    "            \n",
    "            if type(ith_nonlm[0])==str:\n",
    "                print(np.array(ith_nonlm).dtype)\n",
    "                out_image = out_image.astype(np.array(ith_nonlm).dtype)\n",
    "            \n",
    "            for r in range(108):\n",
    "                for c in range(144):\n",
    "                    if (r%12 in [*range(3,9)]) and (c%12 in [*range(3,8)]): continue\n",
    "                    else:\n",
    "                        if cnt >= len(ith_nonlm): continue\n",
    "                        out_image[r,c]= ith_nonlm[cnt]\n",
    "                        cnt += 1\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid length of lmids: {num_lm}\")\n",
    "        lst.append(out_image)\n",
    "    return lst\n",
    "\n",
    "def image_to_rnaseq(image, lmids, all_gene_ids):\n",
    "    # image: should be (108x144) numpy ndarray; the code would be able to handle with pandas DataFrame \n",
    "    # lmids, all_gene_ids: list of gene ids or path to the text file of gene ids\n",
    "    # output: (12320x1) numpy ndarray of inferred values\n",
    "    # sanity check\n",
    "    if isinstance(image, pd.DataFrame): image = image.values\n",
    "    elif not isinstance(image, np.ndarray):\n",
    "        raise TypeError(f\"Invalid image type: {type(image)}; image should be pandas DataFrame or numpy array\")\n",
    "    \n",
    "    if not type(lmids)==list:\n",
    "        if type(lmids)==str and lmids.endswith(\".txt\"):\n",
    "            lmids = load_geneid_list(lmids)\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid lmids type: {type(lmids)}; lmids should be list of landmark ids or string of path to landmark ids text file\")\n",
    "\n",
    "    if not type(all_gene_ids)==list:\n",
    "        if type(all_gene_ids)==str and all_gene_ids.endswith(\".txt\"):\n",
    "            all_gene_ids = load_geneid_list(all_gene_ids)\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid all_gene_ids type: {type(all_gene_ids)}; all_gene_ids should be list of gene ids or string of path to gene ids text file\")\n",
    "\n",
    "\n",
    "    # produce an array indicating which gene id is allocated to the cell\n",
    "    id_df = pd.DataFrame(all_gene_ids, index=all_gene_ids)\n",
    "    id_arr = rnaseq_to_image(id_df, lmids)[0]\n",
    "\n",
    "    if id_arr.shape != image.shape:\n",
    "        raise ValueError(f\"Invalid input image shape: {image.shape}\")\n",
    "    \n",
    "    # get the inferred values from image\n",
    "    display(id_arr)\n",
    "    inferred_dict = {}\n",
    "    for r in range(image.shape[0]):\n",
    "        for c in range(image.shape[1]):\n",
    "            if id_arr[r,c] in all_gene_ids:\n",
    "                if id_arr[r,c] in inferred_dict.keys():\n",
    "                    inferred_dict[id_arr[r,c]].append(image[r,c])\n",
    "                else:\n",
    "                    inferred_dict[id_arr[r,c]] = [image[r,c]]\n",
    "    \n",
    "    # if a gene is inferred by multiple pixels, use the average of values as the inferred\n",
    "    inferred_arr = []\n",
    "    for i in all_gene_ids:\n",
    "        lst = inferred_dict[i]\n",
    "        inferred_arr.append([np.mean(lst)])\n",
    "    \n",
    "    return np.array(inferred_arr)\n",
    "\n",
    "def produce_training_images(L1000_gctx, RNAseq_gctx, outpath, lmids,\n",
    "                            train=2500, valid=500, test=176):\n",
    "    # From gctx files (GTEx; 12320x3176) produce SwinIR-compatible images (.csv files)\n",
    "    # result: image files will be written as: \n",
    "    # outpath/(L1000 or RNAseq)/(train, valid or test)/*.csv\n",
    "    \n",
    "    # load required data\n",
    "    if type(lmids)==str and lmids.endswith('.txt'):\n",
    "        lmids = load_geneid_list(lmids)\n",
    "    l1000 = parse(L1000_gctx).data_df.loc[lmids,:]\n",
    "    rnaseq = parse(RNAseq_gctx).data_df\n",
    "    if not os.path.exists(outpath): os.makedirs(outpath)\n",
    "    \n",
    "    # scaling to (0,1)\n",
    "    l1000_scaled = l1000 / np.max(l1000)\n",
    "    l1000_image_list = l1000_to_image(l1000_scaled, lmids)\n",
    "    rnaseq_scaled = rnaseq / np.max(rnaseq)\n",
    "    rnaseq_image_list = rnaseq_to_image(rnaseq_scaled, lmids)\n",
    "    \n",
    "    # Save L1000 images\n",
    "    for i in range(len(l1000_image_list)):\n",
    "        outpath_L1000 = os.path.join(outpath, \"L1000\")\n",
    "        # By column numbers, images are divided into three distinct directories\n",
    "        if i < train:\n",
    "            this_outpath = os.path.join(outpath_L1000,\"train\")\n",
    "        elif i < train+valid:\n",
    "            this_outpath = os.path.join(outpath_L1000, 'valid')\n",
    "        elif i < train+valid+test:\n",
    "            this_outpath = os.path.join(outpath_L1000, 'test')\n",
    "        outfilename = os.path.join(this_outpath,f\"{i:04d}.csv\") # 0000.csv ~ 3175.csv\n",
    "        if not os.path.exists(this_outpath): os.makedirs(this_outpath)\n",
    "        np.savetxt(outfilename, l1000_image_list[i], delimiter=\",\")\n",
    "    \n",
    "    # Save RNAseq images\n",
    "    for i in range(len(rnaseq_image_list)):\n",
    "        outpath_RNAseq = os.path.join(outpath, \"RNAseq\")\n",
    "        if i < train:\n",
    "            this_outpath = os.path.join(outpath_RNAseq,\"train\")\n",
    "        elif i < train+valid:\n",
    "            this_outpath = os.path.join(outpath_RNAseq, 'valid')\n",
    "        elif i < train+valid+test:\n",
    "            this_outpath = os.path.join(outpath_RNAseq, 'test')\n",
    "        outfilename = os.path.join(this_outpath,f\"{i:04d}.csv\") # 0000.csv ~ 3175.csv\n",
    "        if not os.path.exists(this_outpath): os.makedirs(this_outpath)\n",
    "        np.savetxt(outfilename, rnaseq_image_list[i], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Produce L1000/RNAseq images (~10 min)\n",
    "produce_training_images(L1000_gctx=\"L1000_n3176x12320.gctx\", RNAseq_gctx=\"RNAseq_n3176x12320.gctx\",\n",
    "                        outpath='/content/', lmids=\"lmid_970.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31676,
     "status": "ok",
     "timestamp": 1734487824564,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "jckOznnm6Ul3",
    "outputId": "9923f08e-5b53-4925-c731-bc2e65952d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "loading model from /content/320000_E.pth\n",
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/content/KAIR_harim/test_swinir.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_model = torch.load(args.model_path)\n",
      "\n",
      "/content/inferred/ \n",
      "-- Average PSNR/SSIM(RGB): 76.33 dB; 1.0000\n"
     ]
    }
   ],
   "source": [
    "# @title Infer with test images\n",
    "\n",
    "main_text = \"python KAIR_L1000/test_swinir.py --task SwinIR --scale 4 --training_patch_size 24 \" #default for reproducing \n",
    "lq_arg = f\"--folder_lq /content/L1000/test \" #L1000 \n",
    "gt_arg = f\"--folder_gt /content/RNAseq/test \" #GT for evaluation metric \n",
    "model_arg = f\"--model_path /content/320000_E.pth \" # your model path\n",
    "output_arg = f\"--folder_output /content/inferred/ \" #output path\n",
    "\n",
    "!{main_text + model_arg + lq_arg + gt_arg + output_arg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359257,
     "status": "ok",
     "timestamp": 1734488241373,
     "user": {
      "displayName": "Baek Laboratory",
      "userId": "07309149725431453632"
     },
     "user_tz": -540
    },
    "id": "nnR88ci_6j4w",
    "outputId": "02526ec9-5d7f-4c98-d76d-d7eaaaf1d4b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [05:57<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# @title Convert test images to gene expression values (~6 min)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "fnlist = os.listdir(\"inferred\")\n",
    "fnlist = np.sort(fnlist)\n",
    "result = []\n",
    "lmid_970 = load_geneid_list(\"lmid_970.txt\")\n",
    "for fn in tqdm(fnlist):\n",
    "  arr = pd.read_csv(os.path.join(\"inferred\", fn), header=None).to_numpy()\n",
    "  result.append(image_to_rnaseq(image=arr, lmids=lmid_970, all_gene_ids=parse(\"L1000_n3176x12320.gctx\").data_df.index.tolist()).tolist())\n",
    "inferred_arr = np.array(result).T.squeeze()\n",
    "\n",
    "with open(\"inferred.pkl\", 'wb') as f:\n",
    "  pickle.dump(inferred_arr, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNofvMid/BPi6A4O8dP5ZeO",
   "gpuType": "T4",
   "mount_file_id": "1DGsdXRNTNJod858XNUdFlwUg9N-Bm4PI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
